{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9609bae2-2768-4e58-ab32-0e6688937f6a",
   "metadata": {},
   "source": [
    "This notebooks is created using Chapter 1 of the the [Advanced NLP with spaCy](https://course.spacy.io/en/chapter1) course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0106f3b-10a1-41b1-80d2-79b90b52d8f8",
   "metadata": {},
   "source": [
    "# Chapter 1: Finding words, phrases, names and concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06492884-7109-4650-bf56-13e48fa853a8",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7eff9e-fca6-4ce1-978d-596ca343c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy\n",
    "import spacy\n",
    "\n",
    "# Create the English nlp object\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7f6686-ef83-479f-a400-eb8625657e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Grüße!\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy\n",
    "import spacy\n",
    "\n",
    "# Create the German nlp object\n",
    "nlp = spacy.blank(\"de\")\n",
    "\n",
    "# Process a text (this is German for: \"Kind regards!\")\n",
    "doc = nlp(\"Liebe Grüße!\")\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c2eda4-7bc3-48e9-96eb-46581313071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy\n",
    "import spacy\n",
    "\n",
    "# Create the Spanish nlp object\n",
    "nlp = spacy.blank(\"es\")\n",
    "\n",
    "# Process a text (this is Spanish for: \"How are you?\")\n",
    "doc = nlp(\"¿Cómo estás?\")\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c863116-d7c2-4529-9502-7fcd1a9c305b",
   "metadata": {},
   "source": [
    "## Documents, spans and tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4264b5e1-696b-4fbe-b45f-4e4267c8a667",
   "metadata": {},
   "source": [
    "When you call nlp on a string, spaCy first tokenizes the text and creates a document object. In this exercise, you’ll learn more about the Doc, as well as its views Token and Span.\n",
    "\n",
    "Step 1\n",
    "\n",
    "Use spacy.blank to create the English nlp object.\n",
    "\n",
    "Process the text and instantiate a Doc object in the variable doc.\n",
    "\n",
    "Select the first token of the Doc and print its text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18224070-2fb4-4413-8b94-3ac07873f6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy and create the English nlp object\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# Select the first token\n",
    "first_token = doc[0]\n",
    "\n",
    "# Print the first token's text\n",
    "print(first_token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c8f17-3d4c-4cd9-babd-e894be5dcdbd",
   "metadata": {},
   "source": [
    "Step 2\n",
    "\n",
    "Use spacy.blank to create the English nlp object.\n",
    "\n",
    "Process the text and instantiate a Doc object in the variable doc.\n",
    "\n",
    "Create a slice of the Doc for the tokens “tree kangaroos” and “tree kangaroos and narwhals”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ca648d-24c4-4ace-89ce-a23977153e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos\n",
      "tree kangaroos and narwhals\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy and create the English nlp object\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos\"\n",
    "tree_kangaroos = doc[2:4]\n",
    "print(tree_kangaroos.text)\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos and narwhals\" (without the \".\")\n",
    "tree_kangaroos_and_narwhals = doc[2:-1]\n",
    "print(tree_kangaroos_and_narwhals.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bfcafc-93c2-4e88-8f81-bebadf26106e",
   "metadata": {},
   "source": [
    "## Lexical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6887a6c-7387-4d56-91dc-1b913faeb5d8",
   "metadata": {},
   "source": [
    "In this example, you’ll use spaCy’s Doc and Token objects, and lexical attributes to find percentages in a text. You’ll be looking for two subsequent tokens: a number and a percent sign.\n",
    "\n",
    "Use the like_num token attribute to check whether a token in the doc resembles a number.\n",
    "\n",
    "Get the token following the current token in the document. The index of the next token in the doc is token.i + 1.\n",
    "\n",
    "Check whether the next token’s text attribute is a percent sign ”%“.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d14719d-2184-48c3-a1e7-2e73095bd02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage found: 60\n",
      "Percentage found: 4\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if token.like_num:\n",
    "        # Get the next token in the document\n",
    "        next_token = doc[token.i + 1]\n",
    "        # Check if the next token's text equals \"%\"\n",
    "        if next_token.text == \"%\":\n",
    "            print(\"Percentage found:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1278c97f-8b40-4dfa-99df-f7af2a6cf278",
   "metadata": {},
   "source": [
    "## Trained pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f21164-e9e0-4a55-92a6-34738dd3d0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
