{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24e7443-3d1e-47db-b10f-a6e07515c321",
   "metadata": {},
   "source": [
    "This notebooks is created using Chapter 2 of the the [Advanced NLP with spaCy](https://course.spacy.io/en/chapter2) course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00edf023-0d9c-4c30-b81f-1dd12b45b65d",
   "metadata": {},
   "source": [
    "# Chapter 2: Large-scale data analysis with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7950db9-5caf-4759-b008-612ac73e25a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643ca3a-6c9b-4f41-9e86-4ef5ab2eaa2d",
   "metadata": {},
   "source": [
    "### Shared vocab and string store (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ac448-5222-48e5-b554-993f0bb50871",
   "metadata": {},
   "source": [
    "spaCy stores all shared data in a vocabulary, the Vocab.\n",
    "\n",
    "This includes words, but also the labels schemes for tags and entities.\n",
    "\n",
    "To save memory, all strings are encoded to hash IDs. If a word occurs more than once, we don't need to save it every time.\n",
    "\n",
    "Instead, spaCy uses a hash function to generate an ID and stores the string only once in the string store. The string store is available as `nlp.vocab.strings`.\n",
    "\n",
    "It's a lookup table that works in both directions. You can look up a string and get its hash, and look up a hash to get its string value. Internally, spaCy only communicates in hash IDs.\n",
    "\n",
    "Hash IDs can't be reversed, though. If a word is not in the vocabulary, there's no way to get its string. That's why we always need to pass around the shared vocab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067ffef-c630-4b68-a015-0986e9ea61b2",
   "metadata": {},
   "source": [
    "- `Vocab`: stores data shared across multiple documents\n",
    "- To save memory, spaCy encodes all strings to hash values\n",
    "- Strings are only stored once in the `StringStore` via `nlp.vocab.strings`\n",
    "- String store: **lookup** table in both directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f744e71f-ae83-43a6-b793-46d33489408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy\n",
    "import spacy\n",
    "\n",
    "# Create a blank English nlp object\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cc4983-3346-4149-9e3e-4cf488b457f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings.add(\"coffee\")\n",
    "coffee_hash = nlp.vocab.strings[\"coffee\"]\n",
    "coffee_string = nlp.vocab.strings[coffee_hash]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84c16a-cf6d-47bb-91d1-62b9df494550",
   "metadata": {},
   "source": [
    "- Hashes can't be reversed – that's why we need to provide the shared vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a638536-7b5b-4291-8097-957138fdc88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3197928453018144401"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c05acc8-1edc-423f-9e4b-5a44de6aa522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raises an error if we haven't seen the string before\n",
    "string = nlp.vocab.strings[3197928453018144401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed798870-d0b7-4e6a-b6d0-0cd216c27bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coffee'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0711877d-3bb9-4dd1-90d7-23b8c2c13759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.strings.StringStore at 0x7c4eb8ddc7b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13592a1-d93a-4e34-b880-747b44734d9c",
   "metadata": {},
   "source": [
    "### Shared vocab and string store (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996cf25-8045-4678-81b7-5aa07ff623af",
   "metadata": {},
   "source": [
    "To get the hash for a string, we can look it up in `nlp.vocab.strings`.\n",
    "\n",
    "To get the string representation of a hash, we can look up the hash.\n",
    "\n",
    "A `Doc` object also exposes its vocab and strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7181d1-7503-4521-9ab1-97cd69140baf",
   "metadata": {},
   "source": [
    "- Look up the string and hash in `nlp.vocab.strings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05b7eba-8e96-4d75-b9b5-8e3ff1251884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash value: 3197928453018144401\n",
      "string value: coffee\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I love coffee\")\n",
    "print(\"hash value:\", nlp.vocab.strings[\"coffee\"])\n",
    "print(\"string value:\", nlp.vocab.strings[3197928453018144401])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b7ef69-f2de-49a5-9743-a665a33fca7d",
   "metadata": {},
   "source": [
    "- The `doc` also exposes the vocab and strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd9235eb-a812-4736-b32c-68477fc49c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash value: 3197928453018144401\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I love coffee\")\n",
    "print(\"hash value:\", doc.vocab.strings[\"coffee\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b67b0a53-0d0c-4bfa-b494-222e11efc766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash value: 3702023516439754181\n"
     ]
    }
   ],
   "source": [
    "print(\"hash value:\", doc.vocab.strings[\"love\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf7c09-68ed-452f-aeff-20a759f89725",
   "metadata": {},
   "source": [
    "### Lexemes: entries in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618ddaf-796a-4e72-9f6b-8e774b32becf",
   "metadata": {},
   "source": [
    "Lexemes are context-independent entries in the vocabulary.\n",
    "\n",
    "You can get a lexeme by looking up a string or a hash ID in the vocab.\n",
    "\n",
    "Lexemes expose attributes, just like tokens.\n",
    "\n",
    "They hold context-independent information about a word, like the text, or whether the word consists of alphabetic characters.\n",
    "\n",
    "Lexemes don't have part-of-speech tags, dependencies or entity labels. Those depend on the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4e08f-3cff-4451-b889-53a8574befbc",
   "metadata": {},
   "source": [
    "- A Lexeme object is an entry in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7030de62-ec36-4a48-bf51-3c5ba9404926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee 3197928453018144401 True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I love coffee\")\n",
    "lexeme = nlp.vocab[\"coffee\"]\n",
    "\n",
    "# Print the lexical attributes\n",
    "print(lexeme.text, lexeme.orth, lexeme.is_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee0fe8-e5a0-4eef-84ea-fde31c9eb81b",
   "metadata": {},
   "source": [
    "- Contains the context-independent information about a word\n",
    "  - Word text: lexeme.text and lexeme.orth (the hash)\n",
    "  - Lexical attributes like lexeme.is_alpha\n",
    "  - Not context-dependent part-of-speech tags, dependencies or entity labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c505d4-4b16-4514-a325-c751e086c0fa",
   "metadata": {},
   "source": [
    "### Vocab, hashes and lexemes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc7965f-760d-45b6-b9b8-d5fc61c05eca",
   "metadata": {},
   "source": [
    "Here's an example.\n",
    "\n",
    "The Doc contains words in context – in this case, the tokens \"I\", \"love\" and \"coffee\" with their part-of-speech tags and dependencies.\n",
    "\n",
    "Each token refers to a lexeme, which knows the word's hash ID. To get the string representation of the word, spaCy looks up the hash in the string store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea666-8a4f-4c71-8c5d-41cf619e0cdf",
   "metadata": {},
   "source": [
    "![Vocab, hashes and lexemes](./img/vocab_stringstore.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0d1e5-edf3-44f8-a678-13986bb1c736",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Strings to hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a364a9-3796-4314-a051-f2681cb1f899",
   "metadata": {},
   "source": [
    "Part 1\n",
    "- Look up the string “cat” in `nlp.vocab.strings` to get the hash.\n",
    "- Look up the hash to get back the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73842e2d-3a57-48e4-a411-8e2f80e3b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5439657043933447811\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"I have a cat\")\n",
    "\n",
    "# Look up the hash for the word \"cat\"\n",
    "cat_hash = nlp.vocab.strings[\"cat\"]\n",
    "print(cat_hash)\n",
    "\n",
    "# Look up the cat_hash to get the string\n",
    "cat_string = nlp.vocab.strings[cat_hash]\n",
    "print(cat_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ffa8e-7c1e-4585-8224-488bcbf076c2",
   "metadata": {},
   "source": [
    "Part 2\n",
    "- Look up the string label “PERSON” in `nlp.vocab.strings` to get the hash.\n",
    "- Look up the hash to get back the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65bde95c-b31b-4e82-bf5e-fe0cc1d06e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "PERSON\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"David Bowie is a PERSON\")\n",
    "\n",
    "# Look up the hash for the string label \"PERSON\"\n",
    "person_hash = nlp.vocab.strings[\"PERSON\"]\n",
    "print(person_hash)\n",
    "\n",
    "# Look up the person_hash to get the string\n",
    "person_string = nlp.vocab.strings[person_hash]\n",
    "print(person_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dcdf74-24cf-4ba3-a646-cd4d619ef62f",
   "metadata": {},
   "source": [
    "## Vocab, hashes and lexemes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb59d6f-dcc7-425d-9dd2-1052f6dba165",
   "metadata": {},
   "source": [
    "Why does this code throw an error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ac820c5-2ff1-4853-8b6c-9bc5b27814c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2644858412616767388\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"[E018] Can't retrieve string for hash '2644858412616767388'. This usually refers to an issue with the `Vocab` or `StringStore`.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(bowie_id)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Look up the ID for \"Bowie\" in the vocab\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(nlp_de\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mstrings[bowie_id])\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-spacy/lib/python3.12/site-packages/spacy/strings.pyx:162\u001b[0m, in \u001b[0;36mspacy.strings.StringStore.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[E018] Can't retrieve string for hash '2644858412616767388'. This usually refers to an issue with the `Vocab` or `StringStore`.\""
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Create an English and German nlp object\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp_de = spacy.blank(\"de\")\n",
    "\n",
    "# Get the ID for the string 'Bowie'\n",
    "bowie_id = nlp.vocab.strings[\"Bowie\"]\n",
    "print(bowie_id)\n",
    "\n",
    "# Look up the ID for \"Bowie\" in the vocab\n",
    "print(nlp_de.vocab.strings[bowie_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c465c3-6e26-4b66-a158-8a7fd359681b",
   "metadata": {},
   "source": [
    "The string \"Bowie\" isn’t in the German vocab, so the hash can’t be resolved in the string store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f11157-e3bb-4433-ae90-901800a52f1f",
   "metadata": {},
   "source": [
    "Hashes can’t be reversed. To prevent this problem, add the word to the new vocab by processing a text or looking up the string, or use the same vocab to resolve the hash back to a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e13b30-e861-4d88-a446-7f710d31d0c5",
   "metadata": {},
   "source": [
    "## Data Structures(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fd364a-1d97-4d43-8cfd-d963a0796f8f",
   "metadata": {},
   "source": [
    "Now that you know all about the vocabulary and string store, we can take a look at the most important data structure: the `Doc`, and its views `Token` and `Span`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dc1cea-7d42-497a-bc6b-fbd5f9d424b4",
   "metadata": {},
   "source": [
    "### The Doc object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79e78a-cbf1-47b4-8ede-8f67dbcd2022",
   "metadata": {},
   "source": [
    "The `Doc` is one of the central data structures in spaCy. It's created automatically when you process a text with the `nlp` object. But you can also instantiate the class manually.\n",
    "\n",
    "After creating the `nlp` object, we can import the `Doc` class from `spacy.tokens`.\n",
    "\n",
    "Here we're creating a doc from three words. The spaces are a list of boolean values indicating whether the word is followed by a space. Every token includes that information – even the last one!\n",
    "\n",
    "The `Doc` class takes three arguments: the shared vocab, the words and the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "367ced5f-faf2-406a-a00b-fcce176d8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an nlp object\n",
    "import spacy\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Import the Doc class\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# The words and spaces to create the doc from\n",
    "words = [\"Hello\", \"world\", \"!\"]\n",
    "spaces = [True, False, False]\n",
    "\n",
    "# Create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024dddb1-dd57-446d-81c2-f2168bbebe71",
   "metadata": {},
   "source": [
    "### The Span object(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6720eed-4476-42a6-ae8e-fdb94a287f9c",
   "metadata": {},
   "source": [
    "A `Span` is a slice of a doc consisting of one or more tokens. The `Span` takes at least three arguments: the doc it refers to, and the start and end index of the span. Remember that the end index is exclusive!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccadda-119e-4e83-ae90-3a2c4e2f1aaa",
   "metadata": {},
   "source": [
    "![The Span Object](./img/span_indices.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6892d8-7829-4c09-9568-66081568dfea",
   "metadata": {},
   "source": [
    "### The Span object(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16d26e-b49b-46e4-a60b-841eced130db",
   "metadata": {},
   "source": [
    "To create a `Span` manually, we can also import the class from `spacy.tokens`. We can then instantiate it with the doc and the span's start and end index, and an optional label argument.\n",
    "\n",
    "The `doc.ents` are writable, so we can add entities manually by overwriting it with a list of spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "145983e4-d14e-42e6-98fb-d6786b730655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Doc and Span classes\n",
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "# The words and spaces to create the doc from\n",
    "words = [\"Hello\", \"world\", \"!\"]\n",
    "spaces = [True, False, False]\n",
    "\n",
    "# Create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "# Create a span manually\n",
    "span = Span(doc, 0, 2)\n",
    "\n",
    "# Create a span with a label\n",
    "span_with_label = Span(doc, 0, 2, label=\"GREETING\")\n",
    "\n",
    "# Add span to the doc.ents\n",
    "doc.ents = [span_with_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0357cc-8fc3-40bd-ab3e-769b2c81dbef",
   "metadata": {},
   "source": [
    "### Best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29184d-f3cd-43ef-82b0-60c84c6eb31d",
   "metadata": {},
   "source": [
    "A few tips and tricks before we get started:\n",
    "\n",
    "The `Doc` and `Span` are very powerful and optimized for performance. They give you access to all references and relationships of the words and sentences.\n",
    "\n",
    "If your application needs to output strings, make sure to convert the doc as late as possible. If you do it too early, you'll lose all relationships between the tokens.\n",
    "\n",
    "To keep things consistent, try to use built-in token attributes wherever possible. For example, `token.i` for the token index.\n",
    "\n",
    "Also, don't forget to always pass in the shared vocab!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b28ce-31ea-44e7-bd5e-5ba9c174e5eb",
   "metadata": {},
   "source": [
    "- `Doc` and `Span` are very powerful and hold references and relationships of words and sentences\n",
    "  - **Convert result to strings as late as possible**\n",
    "  - **Use token attributes if available** – for example, `token.i` for the token index\n",
    "  \n",
    "- Don't forget to pass in the shared `vocab`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a818b-687e-47b9-a87d-c8cf8e3e9d3e",
   "metadata": {},
   "source": [
    "## Creating a Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f5f97-0e62-4858-8655-28791df83c45",
   "metadata": {},
   "source": [
    "Let’s create some Doc objects from scratch!\n",
    "\n",
    "Part 1\n",
    "\n",
    "Import the `Doc` from `spacy.tokens`.\n",
    "\n",
    "Create a `Doc` from the `words` and `spaces`. Don’t forget to pass in the vocab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df67c7a-8afc-45ab-9e95-1e03c97a1277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy is cool!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Import the Doc class\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Desired text: \"spaCy is cool!\"\n",
    "words = [\"spaCy\", \"is\", \"cool\", \"!\"]\n",
    "spaces = [True, True, False, False]\n",
    "\n",
    "# Create a Doc from the words and spaces\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa6ab8f-f1b5-48f5-9a57-27bf2ad9fe5d",
   "metadata": {},
   "source": [
    "Part 2\n",
    "\n",
    "Import the `Doc` from `spacy.tokens`.\n",
    "\n",
    "Create a `Doc` from the `words` and `spaces`. Don’t forget to pass in the vocab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76808128-b262-4eea-b63a-3643767aa9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go, get started!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Import the Doc class\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Desired text: \"Go, get started!\"\n",
    "words = [\"Go\", \",\", \"get\", \"started\", \"!\"]\n",
    "spaces = [False, True, True, False, False]\n",
    "\n",
    "# Create a Doc from the words and spaces\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab329f6e-bc5f-4d99-8dac-024d06e8b797",
   "metadata": {},
   "source": [
    "Part 3\n",
    "\n",
    "Import the `Doc` from `spacy.tokens`.\n",
    "\n",
    "Complete the `words` and `spaces` to match the desired text and create a `doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b134d7-421d-4184-9603-bb4067a8d035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, really?!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Import the Doc class\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Desired text: \"Oh, really?!\"\n",
    "words = [\"Oh\", \",\", \"really\", \"?\", \"!\"]\n",
    "spaces = [False, True, False, False, False]\n",
    "\n",
    "# Create a Doc from the words and spaces\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cbaea4-1ebe-4eac-a031-0aae255aace2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
