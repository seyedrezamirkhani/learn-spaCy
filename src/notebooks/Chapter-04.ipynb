{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f70c4bc-9e5f-4001-b0ab-c749c7bb9e50",
   "metadata": {},
   "source": [
    "This notebooks is created using Chapter 4 of the the [Advanced NLP with spaCy](https://course.spacy.io/en/chapter4) course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8ffe9-bf98-4cae-8891-717151473048",
   "metadata": {},
   "source": [
    "# Chapter 4: Training a neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0f096-76e4-45cc-b558-fab637914df7",
   "metadata": {},
   "source": [
    "In this chapter, you'll learn how to update spaCy's statistical models to customize them for your use case – for example, to predict a new entity type in online comments. You'll train your own model from scratch, and understand the basics of how training works, along with tips and tricks that can make your custom NLP projects more successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d2905-ff1e-46e3-b473-c18413f51cf6",
   "metadata": {},
   "source": [
    "## Training and updating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b0770-887a-4d03-8b9d-7f892d0194b2",
   "metadata": {},
   "source": [
    "Welcome to the final chapter, which is about one of the most exciting aspects of modern NLP: training your own models!\n",
    "\n",
    "In this lesson, you'll learn about training and updating spaCy's pipeline components and their neural network models, and the data you need for it – focusing specifically on the named entity recognizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c3edd0-d991-46ae-8cc7-e4eaea70da84",
   "metadata": {},
   "source": [
    "### Why update the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e905eaf-639d-4620-b76e-752c99bffb2d",
   "metadata": {},
   "source": [
    "Before we get starting with explaining how, it's worth taking a second to ask ourselves: Why would we want to update the model with our own examples? Why can't we just rely on pre-trained pipelines?\n",
    "\n",
    "Statistical models make predictions based on the examples they were trained on.\n",
    "\n",
    "You can usually make the model more accurate by showing it examples from your domain.\n",
    "\n",
    "You often also want to predict categories specific to your problem, so the model needs to learn about them.\n",
    "\n",
    "This is essential for text classification, very useful for entity recognition and a little less critical for tagging and parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea54cbb-5eb3-44dd-aa76-84cbe7ccaa83",
   "metadata": {},
   "source": [
    "- Better results on your specific domain\n",
    "- Learn classification schemes specifically for your problem\n",
    "- Essential for text classification\n",
    "- Very useful for named entity recognition\n",
    "- Less critical for part-of-speech tagging and dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c15f0f-ff6b-4a24-94d6-53680e1a8ff4",
   "metadata": {},
   "source": [
    "### How training works (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1299cbb4-7959-4251-8269-01f8a3ccdbbd",
   "metadata": {},
   "source": [
    "spaCy supports updating existing models with more examples, and training new models. If we're not starting with a trained pipeline, we first initialize the weights randomly.\n",
    "\n",
    "Next, spaCy calls `nlp.update`, which predicts a batch of examples with the current weights.\n",
    "\n",
    "The model then checks the predictions against the correct answers, and decides how to change the weights to achieve better predictions next time.\n",
    "\n",
    "Finally, we make a small correction to the current weights and move on to the next batch of examples.\n",
    "\n",
    "spaCy then continues calling `nlp.update` for each batch of examples in the data. During training, you usually want to make multiple passes over the data and train until the model stops improving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9be33-1dc3-4361-a096-10ebef2ac03b",
   "metadata": {},
   "source": [
    "1. **Initialize** the model weights randomly\n",
    "2. **Predict** a few examples with the current weights\n",
    "3. **Compare** prediction with true labels\n",
    "4. **Calculate** how to change weights to improve predictions\n",
    "5. **Update** weights slightly\n",
    "6. Go back to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37af80f-c350-47a0-83e1-cab6d815570a",
   "metadata": {},
   "source": [
    "### How training works (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fdcc4-2821-4b7a-a3ee-84858109d12a",
   "metadata": {},
   "source": [
    "Here's an illustration showing the process.\n",
    "\n",
    "The training data are the examples we want to update the model with.\n",
    "\n",
    "The text should be a sentence, paragraph or longer document. For the best results, it should be similar to what the model will see at runtime.\n",
    "\n",
    "The label is what we want the model to predict. This can be a text category, or an entity span and its type.\n",
    "\n",
    "The gradient is how we should change the model to reduce the current error. It's computed when we compare the predicted label to the true label.\n",
    "\n",
    "After training, we can then save out an updated model and use it in our application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52735404-442a-4a02-8561-e8b1d5fce3a3",
   "metadata": {},
   "source": [
    "![training](./img/training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c3e61-ac24-4c46-93d9-701d5021660e",
   "metadata": {},
   "source": [
    "- **Training data**: Examples and their annotations.\n",
    "- **Text**: The input text the model should predict a label for.\n",
    "- **Label**: The label the model should predict.\n",
    "- **Gradient**: How to change the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfebd4c-6d10-4671-a8b2-74f3ace81be7",
   "metadata": {},
   "source": [
    "### Example: Training the entity recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8fef83-ed96-457f-9910-d3d88ef9430c",
   "metadata": {},
   "source": [
    "Let's look at an example for a specific component: the entity recognizer.\n",
    "\n",
    "The entity recognizer takes a document and predicts phrases and their labels in context. This means that the training data needs to include texts, the entities they contain, and the entity labels.\n",
    "\n",
    "Entities can't overlap, so each token can only be part of one entity.\n",
    "\n",
    "The easiest way to do this is to show the model a text and entity spans. spaCy can be updated from regular `Doc` objects with entities annotated as the `doc.ents`. For example, \"iPhone X\" is a gadget, starts at token 0 and ends at token 1.\n",
    "\n",
    "It's also very important for the model to learn words that *aren't* entities.\n",
    "\n",
    "In this case, the list of span annotations will be empty.\n",
    "\n",
    "Our goal is to teach the model to recognize new entities in similar contexts, even if they weren't in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c03b1e-af82-4849-a81b-c654895177a9",
   "metadata": {},
   "source": [
    "- The entity recognizer tags words and phrases in context\n",
    "- Each token can only be part of one entity\n",
    "- Examples need to come with context"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6ac2c59-7708-4e53-b84d-25f6ffb5b308",
   "metadata": {},
   "source": [
    "doc = nlp(\"iPhone X is coming\")\n",
    "doc.ents = [Span(doc, 0, 2, label=\"GADGET\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e0973-8b51-4c99-a32b-7a619d0a5bca",
   "metadata": {},
   "source": [
    "- Texts with no entities are also important"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd8348b7-2092-4502-8be7-7fadef412c16",
   "metadata": {},
   "source": [
    "doc = nlp(\"I need a new phone! Any tips?\")\n",
    "doc.ents = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ff887-9a2a-477a-8356-424cc9d282f1",
   "metadata": {},
   "source": [
    "- **Goal**: teach the model to generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938cce4-79cd-4dd4-840d-f005e1b9d72f",
   "metadata": {},
   "source": [
    "### The training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a8c22-259f-41ff-8eb3-26354bff811e",
   "metadata": {},
   "source": [
    "The training data tells the model what we want it to predict. This could be texts and named entities we want to recognize, tokens and their correct part-of-speech tags or anything else the model should predict.\n",
    "\n",
    "To update an existing model, we can start with a few hundred to a few thousand examples.\n",
    "\n",
    "To train a new category we may need up to a million.\n",
    "\n",
    "spaCy's trained English pipelines for instance were trained on 2 million words labelled with part-of-speech tags, dependencies and named entities.\n",
    "\n",
    "Training data is usually created by humans who assign labels to texts.\n",
    "\n",
    "This is a lot of work, but can be semi-automated – for example, using spaCy's `Matcher`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43bd375-24e4-4ff0-a534-6cd7a30d4ee8",
   "metadata": {},
   "source": [
    "- Examples of what we want the model to predict in context\n",
    "- Update an **existing model**: a few hundred to a few thousand examples\n",
    "- Train a **new category**: a few thousand to a million examples\n",
    "  - spaCy's English models: 2 million words\n",
    "- Usually created manually by human annotators\n",
    "- Can be semi-automated – for example, using spaCy's `Matcher`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd2da22-18f0-4e77-b430-10c77172a983",
   "metadata": {},
   "source": [
    "### Training vs. evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1bd392-de06-43ed-927a-6ac340fe44c3",
   "metadata": {},
   "source": [
    "When training your model, it's important to know how it's doing and whether it's learning the right thing. This is done by comparing the model's predictions on examples it hasn't seen during training to answers we already know. So in addition to the training data, you also need evaluation data, also called development data.\n",
    "\n",
    "The evaluation data is used to calculate how accurate your model is. For example, an accuracy score of 90% means that the model predicted 90% of the evaluation examples correctly.\n",
    "\n",
    "This also means that the evaluation data needs to be representative of the data your model will see at runtime. Otherwise, the accuracy score will be meaningless, because it won't tell you how good your model *really* is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a77ae-c714-4294-aa33-7bcd93d0804a",
   "metadata": {},
   "source": [
    "- **Training data**: used to update the model\n",
    "- **Evaluation data**:\n",
    "  - data the model hasn't seen during training\n",
    "  - used to calculate how accurate the model is\n",
    "  - should be representative of the data the model will see at runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94717ff5-fe97-4d10-aaa0-fd660cf45d06",
   "metadata": {},
   "source": [
    "### Generating a training corpus (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba43402-9007-4dc8-8579-63b7fc324876",
   "metadata": {},
   "source": [
    "spaCy can be updated from data in the same format it creates: `Doc` objects. You already learned all about creating `Doc` and `Span` objects in chapter 2.\n",
    "\n",
    "In this example, we're creating two `Doc` objects for our corpus: one that contains an entity and another one that doesn't contain any entities. To set the entities on the `Doc`, we can add a `Span` to the `doc.ents`.\n",
    "\n",
    "Of course, you'll need a lot more examples to effectively train your model to generalize and predict similar entities in context. Depending on the task, you usually want at least a few hundred to a few thousand representative examples."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a7c6ebe-7e53-449c-a826-f9bd67cafee6",
   "metadata": {},
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create a Doc with entity spans\n",
    "doc1 = nlp(\"iPhone X is coming\")\n",
    "doc1.ents = [Span(doc1, 0, 2, label=\"GADGET\")]\n",
    "# Create another doc without entity spans\n",
    "doc2 = nlp(\"I need a new phone! Any tips?\")\n",
    "\n",
    "docs = [doc1, doc2]  # and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036e7fe4-adeb-42fe-a2bd-55aedaf3ee4d",
   "metadata": {},
   "source": [
    "### Generating a training corpus (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda277d-394d-4cc6-bf77-963d3f3bede3",
   "metadata": {},
   "source": [
    "As I mentioned earlier, we don't just need data to train the model. We also want to evaluate its accuracy on examples it hasn't seen during training. This is usually done by shuffling and splitting your data in two: one portion for training and one for evaluation. Here, we're using a simple 50/50 split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8487358c-f0b8-45ba-ba00-479b581f2b63",
   "metadata": {},
   "source": [
    "- split data into two portions:\n",
    "  - **training data**: used to update the model\n",
    "  - **development data**: used to evaluate the model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30cc072c-4205-4582-954a-1e44fbd7b850",
   "metadata": {},
   "source": [
    "random.shuffle(docs)\n",
    "train_docs = docs[:len(docs) // 2]\n",
    "dev_docs = docs[len(docs) // 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ed45d-d7a4-45f6-9c5e-c22097bbab6e",
   "metadata": {},
   "source": [
    "### Generating a training corpus (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceacc20-32e5-40ea-99cd-612a642426c7",
   "metadata": {},
   "source": [
    "You typically want to store your training and development data as files on disk so you can load them into spaCy's training process.\n",
    "\n",
    "The `DocBin` is a container for efficiently storing and serializing `Doc` objects. You can instantiate it with a list of `Doc` objects and call its `to_disk` method to save it to a binary file. We typically use the file extension `.spacy` for these files.\n",
    "\n",
    "Compared to other binary serialization protocols like `pickle`, the `DocBin` is faster and produces smaller file sizes because it only stores the shared vocabulary once. You can read more about how it works in the [documentation](https://spacy.io/api/docbin)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc05113-9090-4d20-be3c-e79aefd9b962",
   "metadata": {},
   "source": [
    "- `DocBin`: container to efficiently store and save `Doc` objects\n",
    "- can be saved to a binary file\n",
    "- binary files are used for training"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35b1bdbe-3285-4fd5-947d-b9c0c88af7cf",
   "metadata": {},
   "source": [
    "# Create and save a collection of training docs\n",
    "train_docbin = DocBin(docs=train_docs)\n",
    "train_docbin.to_disk(\"./train.spacy\")\n",
    "# Create and save a collection of evaluation docs\n",
    "dev_docbin = DocBin(docs=dev_docs)\n",
    "dev_docbin.to_disk(\"./dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8ec1a-32fc-4a11-b313-88687c4ea9b1",
   "metadata": {},
   "source": [
    "### Tip: Converting your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab2d3a-d6bf-4200-9e1e-8838e7c61081",
   "metadata": {},
   "source": [
    "In some cases, you might already have training and development data in a common format – for example, CoNLL or IOB. spaCy's `convert` command automatically converts these files into spaCy's binary format. It also converts JSON files in the old format used by spaCy v2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34964c2f-7b86-4dd8-bc69-3b5bc7ec3d0e",
   "metadata": {},
   "source": [
    "- `spacy convert` lets you convert corpora in common formats\n",
    "- supports `.conll`, `.conllu`, `.iob` and spaCy's old JSON format"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f918869-a85f-4b62-995e-cfbd53dfa410",
   "metadata": {},
   "source": [
    "$ python -m spacy convert ./train.gold.conll ./corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9eda0e-81e3-4ee2-bcae-554bd3343fbf",
   "metadata": {},
   "source": [
    "## Training and evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc78050-3949-4d7d-b829-7d61d5b230c2",
   "metadata": {},
   "source": [
    "**NOTE:** The question below is not very coherent. The question mentions training and development data, then mentions evaluation data meaning development data. The term development data should be simply replaced with test data in my opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b31d29-f873-4885-90e6-19270c7a7933",
   "metadata": {},
   "source": [
    "To train a model, you typically need training data and development data for evaluation. What is this evaluation data used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76fb940-df36-4754-8800-a93a6648b141",
   "metadata": {},
   "source": [
    "- Provide more training examples as a fallback if the training data isn't enough.\n",
    "\n",
    "- Check predictions on unseen examples and calculate the accuracy score. (Correct)\n",
    "\n",
    "- Define training examples without annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b1d65c-3c57-44e7-8ab6-14ffd432238f",
   "metadata": {},
   "source": [
    "## Creating training data (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d230b-9456-43c0-8093-0ff68e9f5468",
   "metadata": {},
   "source": [
    "spaCy’s rule-based `Matcher` is a great way to quickly create training data for named entity models. A list of sentences is available as the variable `TEXTS`. You can print it to inspect it. We want to find all mentions of different iPhone models, so we can create training data to teach a model to recognize them as `\"GADGET\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee2ded-c507-43ef-999b-c462758a9dea",
   "metadata": {},
   "source": [
    "- Write a pattern for two tokens whose lowercase forms match `\"iphone\"` and `\"x\"`.\n",
    "- Write a pattern for two tokens: one token whose lowercase form matches `\"iphone\"` and a digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9713749-621a-4671-8cff-8fc354736f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iPhone X]\n",
      "[iPhone X]\n",
      "[iPhone X]\n",
      "[iPhone 8]\n",
      "[iPhone 11, iPhone 8]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "with open(\"../../exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match \"iphone\" and \"x\"\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "# Token whose lowercase form matches \"iphone\" and a digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Add patterns to the matcher and create docs with matched entities\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    print(spans)\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e4d78-c2cf-4c9f-a4c2-2dbecbae2a47",
   "metadata": {},
   "source": [
    "## Creating training data (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188473ba-467c-4d50-bde3-0695f870a3f7",
   "metadata": {},
   "source": [
    "After creating the data for our corpus, we need to save it out to a `.spacy` file. The code from the previous example is already available.\n",
    "\n",
    "- Instantiate the `DocBin` with the list of `docs`.\n",
    "- Save the `DocBin` to a file called `train.spacy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9e06ae4-f2c6-48b3-927a-0aed743cae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "\n",
    "with open(\"../../exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add patterns to the matcher\n",
    "pattern1 = ([{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}])\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)\n",
    "\n",
    "doc_bin = DocBin(docs=docs)\n",
    "doc_bin.to_disk(\"./train.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef75952-74b2-46c6-b406-e1298bf3142d",
   "metadata": {},
   "source": [
    "## Configuring and running training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239fbd9a-66b8-4623-a2d2-603f097c7f7c",
   "metadata": {},
   "source": [
    "Now that you've learned how to create training data, let's take a look at training your pipeline and configuring the training. In this lesson, you'll learn all about spaCy's training config system, how to generate your own training config, how to use the CLI to train a model and how to explore your trained pipeline afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb0b0f-bc37-40a1-86a2-4ef9682f84c7",
   "metadata": {},
   "source": [
    "### The training config (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c55438-0d57-4e60-92c1-5532799e5c39",
   "metadata": {},
   "source": [
    "spaCy uses a config file, usually called `config.cfg`, as the \"single source of truth\" for all settings. The config file defines how to initialize the `nlp` object, which pipeline components to add and how their internal model implementations should be configured. It also includes all settings for the training process and how to load the data, including hyperparameters.\n",
    "\n",
    "Instead of providing lots of arguments on the command line or having to remember to define every single setting in code, you only need to pass your config file to spaCy's training command.\n",
    "\n",
    "Config files also help with reproducibility: you'll have all settings in one place and always know how your pipeline was trained. You can even check your config file into a Git repo to version it and share it with others so they can train the same pipeline with the same settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84b2d7b-3bc7-4604-8fa9-3119d21bcb58",
   "metadata": {},
   "source": [
    "- **single source of truth** for all settings\n",
    "- typically called `config.cfg`\n",
    "- defines how to initialize the `nlp` object\n",
    "- includes all settings about the pipeline components and their model implementations\n",
    "- configures the training process and hyperparameters\n",
    "- makes your training more reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37cb438-9902-470f-8fde-dba6eb3a20a4",
   "metadata": {},
   "source": [
    "### The training config (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83501a-053d-4009-beaa-8184cf27e0ae",
   "metadata": {},
   "source": [
    "Here's an excerpt from a config file used to train a pipeline with a named entity recognizer. The config is grouped into sections, and nested sections are defined using a dot. For example, `[components.ner.model]` defines the settings for the named entity recognizer's model implementation.\n",
    "\n",
    "Config files can also reference Python functions using the `@` notation. For example, the tokenizer defines a registered tokenizer function. You can use this to customize different parts of the `nlp` object and training – from plugging in your own tokenizer, all the way to implementing your own model architectures. But let's not worry about this for now – what you'll learn in this chapter will simply use the defaults spaCy provides out-of-the-box!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ce9d09c-6735-45b6-b3db-0d330405cffc",
   "metadata": {},
   "source": [
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"tok2vec\", \"ner\"]\n",
    "batch_size = 1000\n",
    "\n",
    "[nlp.tokenizer]\n",
    "@tokenizers = \"spacy.Tokenizer.v1\"\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.ner]\n",
    "factory = \"ner\"\n",
    "\n",
    "[components.ner.model]\n",
    "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
    "hidden_width = 64\n",
    "# And so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebdae5-91f6-4fe3-9178-668809634c48",
   "metadata": {},
   "source": [
    "### Generating a config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ec2f5-181f-4ec5-a774-b0a918318203",
   "metadata": {},
   "source": [
    "Of course, you don't have to write the config files by hand, and in a lot of cases, you won't even need to customize it at all. spaCy can auto-generate a config file for you.\n",
    "\n",
    "The quickstart widget in the documentation lets you generate a config interactively by selecting the language and pipeline components you need, as well as optional hardware and optimization settings.\n",
    "\n",
    "Alternatively, you can also use spaCy's built-in `init config` command. It takes the output file as the first argument. We usually call this file `config.cfg`. The argument `--lang` defines the language class that should be used for the pipeline, for example, `en` for English. The `--pipeline` argument lets you specify one or more comma-separated pipeline components to include. In this example, we're creating a config with one pipeline component, the named entity recognizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc59902-f5d3-4a73-84ef-a5eae764f91a",
   "metadata": {},
   "source": [
    "- spaCy can auto-generate a default config file for you\n",
    "- interactive [quickstart widget](https://spacy.io/usage/training#quickstart) in the docs\n",
    "- [init config](https://spacy.io/api/cli#init-config) command on the CLI"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8901d827-069f-42b8-872a-b9d4da78059e",
   "metadata": {},
   "source": [
    "$ python -m spacy init config ./config.cfg --lang en --pipeline ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edaf00-62b1-4470-a916-a83dede91b98",
   "metadata": {},
   "source": [
    "- `init config`: the command to run\n",
    "- `config.cfg`: output path for the generated config\n",
    "- `--lang`: language class of the pipeline, e.g. `en` for English\n",
    "- `--pipeline`: comma-separated names of components to include"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af0d65-e827-4fc9-b4e4-d1e18d6ea60f",
   "metadata": {},
   "source": [
    "### Training a pipeline (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9a4fc-8dfb-4cff-90a8-6f8b6f84d042",
   "metadata": {},
   "source": [
    "To train a pipeline, all you need is the config file and the training and development data. These are the `.spacy` files you already worked with in the previous exercises.\n",
    "\n",
    "The first argument of `spacy train` is the path to the config file. The `--output` argument lets you specify a directory for saving the final trained pipeline.\n",
    "\n",
    "You can also override different config settings on the command line. In this case, we override `paths.train` using the path to the `train.spacy` file and `paths.dev` using the `dev.spacy` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa4902-e9cc-4cae-9e91-e7aab502b16d",
   "metadata": {},
   "source": [
    "- all you need is the `config.cfg` and the training and development data\n",
    "- config settings can be overwritten on the command line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b90ce-d681-4398-ab3b-12cf3979cea4",
   "metadata": {},
   "source": [
    "`$ python -m spacy train ./config.cfg --output ./output --paths.train train.spacy --paths.dev dev.spacy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb14bea4-8827-4165-9986-78b6f337958d",
   "metadata": {},
   "source": [
    "- `train`: the command to run\n",
    "- `config.cfg`: the path to the config file\n",
    "- `--output`: the path to the output directory to save the trained pipeline\n",
    "- `--paths.train`: override with path to the training data\n",
    "- `--paths.dev`: override with path to the evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0ec46-ab84-46e3-87b5-ad1f8967b55c",
   "metadata": {},
   "source": [
    "**NOTE**: Again there is mixing names between dev and evaluation data which should both be test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9032337c-ac66-44d0-b25a-512cae05b95c",
   "metadata": {},
   "source": [
    "### Training a pipeline (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6e156-b7b0-468e-8462-6b452981c3bb",
   "metadata": {},
   "source": [
    "Here's an example of the output you'll see during and after training. You might remember from earlier in this chapter that you usually want to make several passes over the data during training. Each pass over the data is also called an \"epoch\". This is shown in the first column of the table.\n",
    "\n",
    "Within each epoch, spaCy outputs the accuracy scores every 200 examples. These are the steps shown in the second column. You can change the frequency in the config. Each line shows the loss and calculated accuracy score at this point during training.\n",
    "\n",
    "The most interesting score to keep an eye on is the combined score in the last column. It reflects how accurately your model predicted the correct answers in the evaluation data.\n",
    "\n",
    "The training runs until the model stops improving and exits automatically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f14e0-0efe-4d4d-94bb-f821bcf02960",
   "metadata": {},
   "source": [
    "```\n",
    "============================ Training pipeline ============================\n",
    "ℹ Pipeline: ['tok2vec', 'ner']\n",
    "ℹ Initial learn rate: 0.001\n",
    "\n",
    "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE\n",
    "---  ------  ------------  --------  ------  ------  ------  ------\n",
    "  0       0          0.00     26.50    0.73    0.39    5.43    0.01\n",
    "  0     200         33.58    847.68   10.88   44.44    6.20    0.11\n",
    "  1     400         70.88    267.65   33.50   45.95   26.36    0.33\n",
    "  2     600         67.56    156.63   45.32   62.16   35.66    0.45\n",
    "  3     800        138.28    134.12   48.17   74.19   35.66    0.48\n",
    "  4    1000        177.95    109.77   51.43   66.67   41.86    0.51\n",
    "  6    1200         94.95     52.13   54.63   67.82   45.74    0.55\n",
    "  8    1400        126.85     66.19   56.00   65.62   48.84    0.56\n",
    " 10    1600         38.34     24.16   51.96   70.67   41.09    0.52\n",
    " 13    1800        105.14     23.23   56.88   69.66   48.06    0.57\n",
    "\n",
    "✔ Saved pipeline to output directory\n",
    "/path/to/output/model-last\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07d67e-af14-43c8-91ea-a1595707771c",
   "metadata": {},
   "source": [
    "**NOTE**: Again there is mixing names between dev and evaluation data which should both be test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7925959-988a-4435-9db0-ecfbfa812035",
   "metadata": {},
   "source": [
    "### Loading a trained pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263e41bb-94ce-4d5c-9bbf-4951288866ff",
   "metadata": {},
   "source": [
    "The pipeline saved after training is a regular loadable spaCy pipeline – just like the trained pipelines provided by spaCy, for example `en_core_web_sm`. At the end, the last trained pipeline and the pipeline with the best score is saved to the output directory.\n",
    "\n",
    "You can load your trained pipeline by passing the path to `spacy.load`. You can then use it to process and analyze text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cfd70d-caca-4fb6-91a0-a4fa9caa919b",
   "metadata": {},
   "source": [
    "- output after training is a regular loadable spaCy pipeline\n",
    "  - `model-last`: last trained pipeline\n",
    "  - `model-best`: best trained pipeline\n",
    "- load it with `spacy.load`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0c8fa-890e-471e-aae0-7c8743dcd24b",
   "metadata": {},
   "source": [
    "```\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"/path/to/output/model-best\")\n",
    "doc = nlp(\"iPhone 11 vs iPhone 8: What's the difference?\")\n",
    "print(doc.ents)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2aff5e-ebbd-4f50-9403-7290b52e4dd4",
   "metadata": {},
   "source": [
    "### Tip: Packaging your pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa8918-68df-43cb-8cfb-3ece6938447c",
   "metadata": {},
   "source": [
    "To make it easy to deploy your pipelines, spaCy provides a handy command to package them as Python packages. The `spacy package` command takes the path to your exported pipeline and an output directory. It then generates a Python package containing your pipeline. The Python package is a `.tar.gz` file and can be installed into your environment.\n",
    "\n",
    "You can also provide an optional name and version on the command. This lets you manage multiple different versions of a pipeline, for example, if you decide to customize your pipeline later or train it with more data.\n",
    "\n",
    "The package behaves just like any other Python package. After installation, you can load your pipeline using its name. Note that spaCy will automatically add the language code to the name. So your pipeline `my_pipeline` will become `en_my_pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07004bd1-8bf3-44e4-aaf5-1dd47ad77e8f",
   "metadata": {},
   "source": [
    "- [spacy package](https://spacy.io/api/cli#package): create an installable Python package containing your pipeline\n",
    "- easy to version and deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba76d7-d98e-41a2-9034-dd775124f12d",
   "metadata": {},
   "source": [
    "```\n",
    "$ python -m spacy package /path/to/output/model-best ./packages --name my_pipeline --version 1.0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0483c-e34d-4dd5-adb0-496f38ad80ae",
   "metadata": {},
   "source": [
    "```\n",
    "$ cd ./packages/en_my_pipeline-1.0.0\n",
    "$ pip install dist/en_my_pipeline-1.0.0.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d925bdb8-74ef-4d98-850e-1bece0e7d2f8",
   "metadata": {},
   "source": [
    "Load and use the pipeline after installation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4fc26c-39b6-498d-b89b-af1cf446473e",
   "metadata": {},
   "source": [
    "``` nlp = spacy.load(\"en_my_pipeline\") ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b20c9b-56fc-4294-8ef3-2b4e33c25e2d",
   "metadata": {},
   "source": [
    "## The training config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2daf1d-0a66-4615-98cf-7b3847e11af9",
   "metadata": {},
   "source": [
    "The `config.cfg` file is the “single source of truth” for training a pipeline with spaCy. Which of the following is not true about the config?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a65c3-35ed-4c78-8f56-d8767fe0529a",
   "metadata": {},
   "source": [
    "- It allows you to configure the training process and hyperparameters.\n",
    "\n",
    "- It helps make your training more reproducible.\n",
    "\n",
    "- It creates an installable Python package with your pipeline. (Correct)\n",
    "\n",
    "- It defines the pipeline's components and their settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a5a6c8-cce5-422f-be30-4533d016fcf0",
   "metadata": {},
   "source": [
    "The config file includes all settings related to training and how to set up the pipeline, but it doesn’t package your pipeline. To create an installable Python package, you can use the `spacy package` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d05da-d298-4a03-921f-63b2297f191c",
   "metadata": {},
   "source": [
    "## Generating a config file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2d3a8-cbdc-4593-bfb2-3bcfb085510e",
   "metadata": {},
   "source": [
    "The [`init config` command](https://spacy.io/api/cli#init-config) auto-generates a config file for training with the default settings. We want to train a named entity recognizer, so we’ll generate a config file for one pipeline component, `ner`. Because we’re executing the command in a Jupyter environment in this course, we’re using the prefix `!`. If you’re running the command in your local terminal, you can leave this out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a6913-ff33-483b-bd3e-a26a4d971f52",
   "metadata": {},
   "source": [
    "Part 1\n",
    "\n",
    "- Use spaCy’s `init config` command to auto-generate a config for an English pipeline.\n",
    "- Save the config to a file `config.cfg`.\n",
    "- Use the `--pipeline` argument to specify one pipeline component, `ner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c43b1e9-40ea-4fd7-af0a-f45ee36332fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config ./config.cfg --lang en --pipeline ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6f529-530d-411c-989d-7ae24c5c335f",
   "metadata": {},
   "source": [
    "Part 2\n",
    "\n",
    "- Let’s take a look at the config spaCy just generated! You can run the command below to print the config to the terminal and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80b459e-c896-4e4c-9094-46e6bcf0bf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths]\n",
      "train = null\n",
      "dev = null\n",
      "vectors = null\n",
      "init_tok2vec = null\n",
      "\n",
      "[system]\n",
      "gpu_allocator = null\n",
      "seed = 0\n",
      "\n",
      "[nlp]\n",
      "lang = \"en\"\n",
      "pipeline = [\"tok2vec\",\"ner\"]\n",
      "batch_size = 1000\n",
      "disabled = []\n",
      "before_creation = null\n",
      "after_creation = null\n",
      "after_pipeline_creation = null\n",
      "tokenizer = {\"@tokenizers\":\"spacy.Tokenizer.v1\"}\n",
      "vectors = {\"@vectors\":\"spacy.Vectors.v1\"}\n",
      "\n",
      "[components]\n",
      "\n",
      "[components.ner]\n",
      "factory = \"ner\"\n",
      "incorrect_spans_key = null\n",
      "moves = null\n",
      "scorer = {\"@scorers\":\"spacy.ner_scorer.v1\"}\n",
      "update_with_oracle_cut_size = 100\n",
      "\n",
      "[components.ner.model]\n",
      "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
      "state_type = \"ner\"\n",
      "extra_state_tokens = false\n",
      "hidden_width = 64\n",
      "maxout_pieces = 2\n",
      "use_upper = true\n",
      "nO = null\n",
      "\n",
      "[components.ner.model.tok2vec]\n",
      "@architectures = \"spacy.Tok2VecListener.v1\"\n",
      "width = ${components.tok2vec.model.encode.width}\n",
      "upstream = \"*\"\n",
      "\n",
      "[components.tok2vec]\n",
      "factory = \"tok2vec\"\n",
      "\n",
      "[components.tok2vec.model]\n",
      "@architectures = \"spacy.Tok2Vec.v2\"\n",
      "\n",
      "[components.tok2vec.model.embed]\n",
      "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
      "width = ${components.tok2vec.model.encode.width}\n",
      "attrs = [\"NORM\",\"PREFIX\",\"SUFFIX\",\"SHAPE\"]\n",
      "rows = [5000,1000,2500,2500]\n",
      "include_static_vectors = false\n",
      "\n",
      "[components.tok2vec.model.encode]\n",
      "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
      "width = 96\n",
      "depth = 4\n",
      "window_size = 1\n",
      "maxout_pieces = 3\n",
      "\n",
      "[corpora]\n",
      "\n",
      "[corpora.dev]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.dev}\n",
      "max_length = 0\n",
      "gold_preproc = false\n",
      "limit = 0\n",
      "augmenter = null\n",
      "\n",
      "[corpora.train]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.train}\n",
      "max_length = 0\n",
      "gold_preproc = false\n",
      "limit = 0\n",
      "augmenter = null\n",
      "\n",
      "[training]\n",
      "dev_corpus = \"corpora.dev\"\n",
      "train_corpus = \"corpora.train\"\n",
      "seed = ${system.seed}\n",
      "gpu_allocator = ${system.gpu_allocator}\n",
      "dropout = 0.1\n",
      "accumulate_gradient = 1\n",
      "patience = 1600\n",
      "max_epochs = 0\n",
      "max_steps = 20000\n",
      "eval_frequency = 200\n",
      "frozen_components = []\n",
      "annotating_components = []\n",
      "before_to_disk = null\n",
      "before_update = null\n",
      "\n",
      "[training.batcher]\n",
      "@batchers = \"spacy.batch_by_words.v1\"\n",
      "discard_oversize = false\n",
      "tolerance = 0.2\n",
      "get_length = null\n",
      "\n",
      "[training.batcher.size]\n",
      "@schedules = \"compounding.v1\"\n",
      "start = 100\n",
      "stop = 1000\n",
      "compound = 1.001\n",
      "t = 0.0\n",
      "\n",
      "[training.logger]\n",
      "@loggers = \"spacy.ConsoleLogger.v1\"\n",
      "progress_bar = false\n",
      "\n",
      "[training.optimizer]\n",
      "@optimizers = \"Adam.v1\"\n",
      "beta1 = 0.9\n",
      "beta2 = 0.999\n",
      "L2_is_weight_decay = true\n",
      "L2 = 0.01\n",
      "grad_clip = 1.0\n",
      "use_averages = false\n",
      "eps = 0.00000001\n",
      "learn_rate = 0.001\n",
      "\n",
      "[training.score_weights]\n",
      "ents_f = 1.0\n",
      "ents_p = 0.0\n",
      "ents_r = 0.0\n",
      "ents_per_type = null\n",
      "\n",
      "[pretraining]\n",
      "\n",
      "[initialize]\n",
      "vectors = ${paths.vectors}\n",
      "init_tok2vec = ${paths.init_tok2vec}\n",
      "vocab_data = null\n",
      "lookups = null\n",
      "before_init = null\n",
      "after_init = null\n",
      "\n",
      "[initialize.components]\n",
      "\n",
      "[initialize.tokenizer]"
     ]
    }
   ],
   "source": [
    "!cat ./config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf95507-8630-4437-8107-325fc7739d82",
   "metadata": {},
   "source": [
    "## Using the training CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d6c5c-b40f-4b8f-bd9d-d48e731dac83",
   "metadata": {},
   "source": [
    "Let’s use the config file generated in the previous exercise and the training corpus we’ve created to train a named entity recognizer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a6daf-dc4a-44d1-b142-41060ccfa5d6",
   "metadata": {},
   "source": [
    "The `train` command lets you train a model from a training config file. A file `config_gadget.cfg` is already available in the directory `exercises/en`, as well as a file `train_gadget.spacy` containing the training examples, and a file `dev_gadget.spacy` containing the evaluation examples. Because we’re executing the command in a Jupyter environment in this course, we’re using the prefix `!`. If you’re running the command in your local terminal, you can leave this out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d003e-aa44-4750-8e45-3cf6badc7966",
   "metadata": {},
   "source": [
    "- Call the `train` command with the file `exercises/en/config_gadget.cfg`.\n",
    "- Save the trained pipeline to a directory `output`.\n",
    "- Pass in the `exercises/en/train_gadget.spacy` and `exercises/en/dev_gadget.spacy` paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4338d1-d74b-47f5-9f10-12e8607b6958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     20.33    1.69    1.04    4.44    0.02\n",
      "  1     200         30.09    985.76   81.32   80.43   82.22    0.81\n",
      "  2     400         71.52    221.11   84.92   85.39   84.44    0.85\n",
      "  4     600         67.26    109.45   81.97   80.65   83.33    0.82\n",
      "  6     800         97.36     96.94   86.34   84.95   87.78    0.86\n",
      "  9    1000         70.54     55.10   83.16   79.00   87.78    0.83\n",
      " 12    1200         46.49     27.38   84.92   85.39   84.44    0.85\n",
      " 16    1400        109.35     30.16   79.79   74.76   85.56    0.80\n",
      " 22    1600         81.64     18.92   84.15   82.80   85.56    0.84\n",
      " 28    1800        126.28     42.64   85.88   87.36   84.44    0.86\n",
      " 36    2000         25.68      6.74   87.15   87.64   86.67    0.87\n",
      " 46    2200         10.60      2.86   87.91   86.96   88.89    0.88\n",
      " 58    2400         20.36      4.09   85.71   88.24   83.33    0.86\n",
      " 70    2600        134.30     38.01   86.19   85.71   86.67    0.86\n",
      " 83    2800        138.90     31.34   83.87   81.25   86.67    0.84\n",
      " 95    3000        116.62     18.51   85.88   87.36   84.44    0.86\n",
      "108    3200         73.26     13.83   85.87   84.04   87.78    0.86\n",
      "120    3400         30.01      3.46   84.49   81.44   87.78    0.84\n",
      "132    3600         37.93      5.64   84.32   82.11   86.67    0.84\n",
      "145    3800         64.76     14.48   84.49   81.44   87.78    0.84\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ../../exercises/en/config_gadget.cfg --output output --paths.train ../../exercises/en/train_gadget.spacy --paths.dev ../../exercises/en/dev_gadget.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017e090e-7bca-4f8b-8e0b-119599af8ac4",
   "metadata": {},
   "source": [
    "## Exploring the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3651b6e-24f5-4ed8-99c9-b3a32628c120",
   "metadata": {},
   "source": [
    "Let’s see how the model performs on unseen data! To speed things up a little, we already ran a trained pipeline for the label `\"GADGET\"` over some text. Here are some of the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c3c5a-cff8-4dd3-be5f-a784e0ba3065",
   "metadata": {},
   "source": [
    "Text |\tEntities\n",
    "-----|----------\n",
    "Apple is slowing down the iPhone 8 and iPhone X - how to stop it\t| (iPhone 8, iPhone X)\n",
    "I finally understand what the iPhone X ‘notch’ is for\t| (iPhone X,)\n",
    "Everything you need to know about the Samsung Galaxy S9\t| (Samsung Galaxy,)\n",
    "Looking to compare iPad models? Here’s how the 2018 lineup stacks up\t| (iPad,)\n",
    "The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple\t| (iPhone 8, iPhone 8)\n",
    "what is the cheapest ipad, especially ipad pro???\t| (ipad, ipad)\n",
    "Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics\t| (Samsung Galaxy,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e12d4-2fd4-4296-aece-c6929ed76e3c",
   "metadata": {},
   "source": [
    "Out of all the entities in the texts, **how many did the model get correct**? Keep in mind that incomplete entity spans count as mistakes, too! Tip: Count the number of entities that the model *should* have predicted. Then count the number of entities it *actually* predicted correctly and divide it by the number of total correct entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db72f6-afa8-4b8a-ad1d-d97f07b6e125",
   "metadata": {},
   "source": [
    "- 45%\n",
    "\n",
    "- 60%\n",
    "\n",
    "- 70% (Correct)\n",
    "\n",
    "- 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9014c37-0d1b-40a0-b2d8-21a012995d5b",
   "metadata": {},
   "source": [
    "Text |\tEntities | Mistake\n",
    "-----|----------|---------\n",
    "Apple is slowing down the iPhone 8 and iPhone X - how to stop it\t| (iPhone 8, iPhone X) |\n",
    "I finally understand what the iPhone X ‘notch’ is for\t| (iPhone X,) |\n",
    "Everything you need to know about the Samsung Galaxy S9\t| (Samsung Galaxy,) | Samsung Galaxy S9\n",
    "Looking to compare iPad models? Here’s how the 2018 lineup stacks up\t| (iPad,) | \n",
    "The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple\t| (iPhone 8, iPhone 8) | iPhone 8 Plus\n",
    "what is the cheapest ipad, especially ipad pro???\t| (ipad, ipad) | ipad pro\n",
    "Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics\t| (Samsung Galaxy,) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58dc161-98d2-43df-92f9-1ee73b6d31cd",
   "metadata": {},
   "source": [
    "## Training best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aec1fd-5a90-4a32-9982-682f50253604",
   "metadata": {},
   "source": [
    "When you start running your own experiments, you might find that a lot of things just don't work the way you want them to. And that's okay.\n",
    "\n",
    "Training models is an iterative process, and you have to try different things until you find out what works best.\n",
    "\n",
    "In this lesson, I'll be sharing some best practices and things to keep in mind when training your own models.\n",
    "\n",
    "Let's take a look at some of the problems you may come across."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9c37c-35c6-447e-94ed-aa37f863c843",
   "metadata": {},
   "source": [
    "### Problem 1: Models can \"forget\" things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26670dfd-e769-4404-bb4f-1da1fa3fca8e",
   "metadata": {},
   "source": [
    "Statistical models can learn lots of things – but they can also unlearn them.\n",
    "\n",
    "If you're updating an existing model with new data, especially new labels, it can overfit and adjust too much to the new examples.\n",
    "\n",
    "For instance, if you're only updating it with examples of `\"WEBSITE\"`, it may \"forget\" other labels it previously predicted correctly – like `\"PERSON\"`.\n",
    "\n",
    "This is also known as the catastrophic forgetting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c798f4-132e-426d-9aae-347f2d090c7a",
   "metadata": {},
   "source": [
    "- Existing model can overfit on new data\n",
    "  - e.g.: if you only update it with `\"WEBSITE\"`, it can \"unlearn\" what a `\"PERSON\"` is\n",
    "- Also known as \"catastrophic forgetting\" problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8184db4-0b79-4c6c-a5e9-ca4664af3575",
   "metadata": {},
   "source": [
    "### Solution 1: Mix in previously correct predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed804bf-cc6e-4950-b990-70e75f25653c",
   "metadata": {},
   "source": [
    "To prevent this, make sure to always mix in examples of what the model previously got correct.\n",
    "\n",
    "If you're training a new category `\"WEBSITE\"`, also include examples of `\"PERSON\"`.\n",
    "\n",
    "spaCy can help you with this. You can create those additional examples by running the existing model over data and extracting the entity spans you care about.\n",
    "\n",
    "You can then mix those examples in with your existing data and update the model with annotations of all labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d96f0-2ae9-412c-b368-f009ede9b36c",
   "metadata": {},
   "source": [
    "- For example, if you're training `\"WEBSITE\"`, also include examples of `\"PERSON\"`\n",
    "- Run existing spaCy model over data and extract all other relevant entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7a7b9-d8a5-4eda-b697-4924eabbb41d",
   "metadata": {},
   "source": [
    "### Problem 2: Models can't learn everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc98e0a8-5ecd-4db3-af3c-2ce3bf35e203",
   "metadata": {},
   "source": [
    "Another common problem is that your model just won't learn what you want it to.\n",
    "\n",
    "spaCy's models make predictions based on the local context – for example, for named entities, the surrounding words are most important.\n",
    "\n",
    "If the decision is difficult to make based on the context, the model can struggle to learn it.\n",
    "\n",
    "The label scheme also needs to be consistent and not too specific.\n",
    "\n",
    "For example, it may be very difficult to teach a model to predict whether something is adult clothing or children's clothing based on the context. However, just predicting the label \"clothing\" may work better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42058666-b76b-47d3-b798-31dca72b79be",
   "metadata": {},
   "source": [
    "- spaCy's models make predictions based on **local context**\n",
    "- Model can struggle to learn if decision is difficult to make based on context\n",
    "- Label scheme needs to be consistent and not too specific\n",
    "  - For example: `\"CLOTHING\"` is better than `\"ADULT_CLOTHING\"` and `\"CHILDRENS_CLOTHING\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04292e2e-7028-4653-8380-eeddbc7d2894",
   "metadata": {},
   "source": [
    "### Solution 2: Plan your label scheme carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbddc7c7-f6e5-4b3d-8048-417d2635643f",
   "metadata": {},
   "source": [
    "Before you start training and updating models, it's worth taking a step back and planning your label scheme.\n",
    "\n",
    "Try to pick categories that are reflected in the local context and make them more generic if possible.\n",
    "\n",
    "You can always add a rule-based system later to go from generic to specific.\n",
    "\n",
    "Generic categories like \"clothing\" or \"band\" are both easier to label and easier to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfee873-eb3d-4587-967a-9b27340731ac",
   "metadata": {},
   "source": [
    "- Pick categories that are reflected in local context\n",
    "- More generic is better than too specific\n",
    "- Use rules to go from generic labels to specific categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee3ef0-8033-45e3-99a0-54a257c97ddf",
   "metadata": {},
   "source": [
    "**BAD:**\n",
    "\n",
    "`LABELS = [\"ADULT_SHOES\", \"CHILDRENS_SHOES\", \"BANDS_I_LIKE\"]`\n",
    "\n",
    "**GOOD:**\n",
    "\n",
    "`LABELS = [\"CLOTHING\", \"BAND\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f79c3-c040-4405-9936-fa6418f9d42e",
   "metadata": {},
   "source": [
    "## Good data vs. bad data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd65c6-bac2-42c0-8cbd-a71bbfd0ebc1",
   "metadata": {},
   "source": [
    "Here’s an excerpt from a training set that labels the entity type `TOURIST_DESTINATION` in traveler reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a40a5-3293-4666-98f5-7743281926be",
   "metadata": {},
   "source": [
    "```\n",
    "doc1 = nlp(\"i went to amsterdem last year and the canals were beautiful\")\n",
    "doc1.ents = [Span(doc1, 3, 4, label=\"TOURIST_DESTINATION\")]\n",
    "\n",
    "doc2 = nlp(\"You should visit Paris once, but the Eiffel Tower is kinda boring\")\n",
    "doc2.ents = [Span(doc2, 3, 4, label=\"TOURIST_DESTINATION\")]\n",
    "\n",
    "doc3 = nlp(\"There's also a Paris in Arkansas, lol\")\n",
    "doc3.ents = []\n",
    "\n",
    "doc4 = nlp(\"Berlin is perfect for summer holiday: great nightlife and cheap beer!\")\n",
    "doc4.ents = [Span(doc4, 0, 1, label=\"TOURIST_DESTINATION\")]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59758d42-f4d6-45d5-a349-ea0bf3bfba18",
   "metadata": {},
   "source": [
    "Part 1\n",
    "\n",
    "Why is this data and label scheme problematic?\n",
    "\n",
    "- Whether a place is a tourist destination is a subjective judgement and not a definitive category. It will be very difficult for the entity recognizer to learn. (Correct)\n",
    "\n",
    "- Paris should also be labelled as tourist destinations for consistency. Otherwise, the model will be confused.\n",
    "\n",
    "- Rare out-of-vocabulary words like the misspelled 'amsterdem' shouldn't be labelled as entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757c551-8252-4277-b8a5-f699facf2317",
   "metadata": {},
   "source": [
    "Answer:\n",
    "The first option is correct.\n",
    "\n",
    "A much better approach would be to only label `\"GPE\"` (geopolitical entity) or `\"LOCATION\"` and then use a rule-based system to determine whether the entity is a tourist destination in this context. For example, you could resolve the entities types back to a knowledge base or look them up in a travel wiki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d42ba-e76c-4dd1-80e5-b10b205b66f7",
   "metadata": {},
   "source": [
    "Part 2\n",
    "\n",
    "- Rewrite the `doc.ents` to only use spans of the label `\"GPE\"` (cities, states, countries) instead of `\"TOURIST_DESTINATION\"`.\n",
    "- Don’t forget to add spans for the `\"GPE\"` entities that weren’t labeled in the old data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9b4d2-3dc2-4d91-9690-7e3f30b5c07a",
   "metadata": {},
   "source": [
    "Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dabc8ef-0ac7-4596-b4c1-0b35d410e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc1 = nlp(\"i went to amsterdem last year and the canals were beautiful\")\n",
    "doc1.ents = [Span(doc1, 3, 4, label=\"TOURIST_DESTINATION\")]\n",
    "\n",
    "doc2 = nlp(\"You should visit Paris once, but the Eiffel Tower is kinda boring\")\n",
    "doc2.ents = [Span(doc2, 3, 4, label=\"TOURIST_DESTINATION\")]\n",
    "\n",
    "doc3 = nlp(\"There's also a Paris in Arkansas, lol\")\n",
    "doc3.ents = []\n",
    "\n",
    "doc4 = nlp(\"Berlin is perfect for summer holiday: great nightlife and cheap beer!\")\n",
    "doc4.ents = [Span(doc4, 0, 1, label=\"TOURIST_DESTINATION\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb8773-4d70-47d2-bda4-27f2621c16c4",
   "metadata": {},
   "source": [
    "Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c2b652-b983-42a3-8694-e63050634b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc1 = nlp(\"i went to amsterdem last year and the canals were beautiful\")\n",
    "doc1.ents = [Span(doc1, 3, 4, label=\"GPE\")]\n",
    "\n",
    "doc2 = nlp(\"You should visit Paris once, but the Eiffel Tower is kinda boring\")\n",
    "doc2.ents = [Span(doc2, 3, 4, label=\"GPE\")]\n",
    "\n",
    "doc3 = nlp(\"There's also a Paris in Arkansas, lol\")\n",
    "doc3.ents = [Span(doc3, 4, 5, label=\"GPE\"), Span(doc2, 6, 7, label=\"GPE\")]\n",
    "\n",
    "doc4 = nlp(\"Berlin is perfect for summer holiday: great nightlife and cheap beer!\")\n",
    "doc4.ents = [Span(doc4, 0, 1, label=\"GPE\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db32b453-ec4b-4e11-bb5a-7630aad7d94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 There\n",
      "1 's\n",
      "2 also\n",
      "3 a\n",
      "4 Paris\n",
      "5 in\n",
      "6 Arkansas\n",
      "7 ,\n",
      "8 lol\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, token in enumerate(doc3):\n",
    "    print(idx, token)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e685d466-d756-42cb-afc5-8fdd4f80cc38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
