{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f70c4bc-9e5f-4001-b0ab-c749c7bb9e50",
   "metadata": {},
   "source": [
    "This notebooks is created using Chapter 4 of the the [Advanced NLP with spaCy](https://course.spacy.io/en/chapter4) course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8ffe9-bf98-4cae-8891-717151473048",
   "metadata": {},
   "source": [
    "# Chapter 4: Training a neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0f096-76e4-45cc-b558-fab637914df7",
   "metadata": {},
   "source": [
    "In this chapter, you'll learn how to update spaCy's statistical models to customize them for your use case – for example, to predict a new entity type in online comments. You'll train your own model from scratch, and understand the basics of how training works, along with tips and tricks that can make your custom NLP projects more successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d2905-ff1e-46e3-b473-c18413f51cf6",
   "metadata": {},
   "source": [
    "## Training and updating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b0770-887a-4d03-8b9d-7f892d0194b2",
   "metadata": {},
   "source": [
    "Welcome to the final chapter, which is about one of the most exciting aspects of modern NLP: training your own models!\n",
    "\n",
    "In this lesson, you'll learn about training and updating spaCy's pipeline components and their neural network models, and the data you need for it – focusing specifically on the named entity recognizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c3edd0-d991-46ae-8cc7-e4eaea70da84",
   "metadata": {},
   "source": [
    "### Why update the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e905eaf-639d-4620-b76e-752c99bffb2d",
   "metadata": {},
   "source": [
    "Before we get starting with explaining how, it's worth taking a second to ask ourselves: Why would we want to update the model with our own examples? Why can't we just rely on pre-trained pipelines?\n",
    "\n",
    "Statistical models make predictions based on the examples they were trained on.\n",
    "\n",
    "You can usually make the model more accurate by showing it examples from your domain.\n",
    "\n",
    "You often also want to predict categories specific to your problem, so the model needs to learn about them.\n",
    "\n",
    "This is essential for text classification, very useful for entity recognition and a little less critical for tagging and parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea54cbb-5eb3-44dd-aa76-84cbe7ccaa83",
   "metadata": {},
   "source": [
    "- Better results on your specific domain\n",
    "- Learn classification schemes specifically for your problem\n",
    "- Essential for text classification\n",
    "- Very useful for named entity recognition\n",
    "- Less critical for part-of-speech tagging and dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c15f0f-ff6b-4a24-94d6-53680e1a8ff4",
   "metadata": {},
   "source": [
    "### How training works (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1299cbb4-7959-4251-8269-01f8a3ccdbbd",
   "metadata": {},
   "source": [
    "spaCy supports updating existing models with more examples, and training new models. If we're not starting with a trained pipeline, we first initialize the weights randomly.\n",
    "\n",
    "Next, spaCy calls `nlp.update`, which predicts a batch of examples with the current weights.\n",
    "\n",
    "The model then checks the predictions against the correct answers, and decides how to change the weights to achieve better predictions next time.\n",
    "\n",
    "Finally, we make a small correction to the current weights and move on to the next batch of examples.\n",
    "\n",
    "spaCy then continues calling `nlp.update` for each batch of examples in the data. During training, you usually want to make multiple passes over the data and train until the model stops improving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9be33-1dc3-4361-a096-10ebef2ac03b",
   "metadata": {},
   "source": [
    "1. **Initialize** the model weights randomly\n",
    "2. **Predict** a few examples with the current weights\n",
    "3. **Compare** prediction with true labels\n",
    "4. **Calculate** how to change weights to improve predictions\n",
    "5. **Update** weights slightly\n",
    "6. Go back to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37af80f-c350-47a0-83e1-cab6d815570a",
   "metadata": {},
   "source": [
    "### How training works (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fdcc4-2821-4b7a-a3ee-84858109d12a",
   "metadata": {},
   "source": [
    "Here's an illustration showing the process.\n",
    "\n",
    "The training data are the examples we want to update the model with.\n",
    "\n",
    "The text should be a sentence, paragraph or longer document. For the best results, it should be similar to what the model will see at runtime.\n",
    "\n",
    "The label is what we want the model to predict. This can be a text category, or an entity span and its type.\n",
    "\n",
    "The gradient is how we should change the model to reduce the current error. It's computed when we compare the predicted label to the true label.\n",
    "\n",
    "After training, we can then save out an updated model and use it in our application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52735404-442a-4a02-8561-e8b1d5fce3a3",
   "metadata": {},
   "source": [
    "![training](./img/training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c3e61-ac24-4c46-93d9-701d5021660e",
   "metadata": {},
   "source": [
    "- **Training data**: Examples and their annotations.\n",
    "- **Text**: The input text the model should predict a label for.\n",
    "- **Label**: The label the model should predict.\n",
    "- **Gradient**: How to change the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfebd4c-6d10-4671-a8b2-74f3ace81be7",
   "metadata": {},
   "source": [
    "### Example: Training the entity recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8fef83-ed96-457f-9910-d3d88ef9430c",
   "metadata": {},
   "source": [
    "Let's look at an example for a specific component: the entity recognizer.\n",
    "\n",
    "The entity recognizer takes a document and predicts phrases and their labels in context. This means that the training data needs to include texts, the entities they contain, and the entity labels.\n",
    "\n",
    "Entities can't overlap, so each token can only be part of one entity.\n",
    "\n",
    "The easiest way to do this is to show the model a text and entity spans. spaCy can be updated from regular `Doc` objects with entities annotated as the `doc.ents`. For example, \"iPhone X\" is a gadget, starts at token 0 and ends at token 1.\n",
    "\n",
    "It's also very important for the model to learn words that *aren't* entities.\n",
    "\n",
    "In this case, the list of span annotations will be empty.\n",
    "\n",
    "Our goal is to teach the model to recognize new entities in similar contexts, even if they weren't in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c03b1e-af82-4849-a81b-c654895177a9",
   "metadata": {},
   "source": [
    "- The entity recognizer tags words and phrases in context\n",
    "- Each token can only be part of one entity\n",
    "- Examples need to come with context"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6ac2c59-7708-4e53-b84d-25f6ffb5b308",
   "metadata": {},
   "source": [
    "doc = nlp(\"iPhone X is coming\")\n",
    "doc.ents = [Span(doc, 0, 2, label=\"GADGET\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e0973-8b51-4c99-a32b-7a619d0a5bca",
   "metadata": {},
   "source": [
    "- Texts with no entities are also important"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd8348b7-2092-4502-8be7-7fadef412c16",
   "metadata": {},
   "source": [
    "doc = nlp(\"I need a new phone! Any tips?\")\n",
    "doc.ents = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ff887-9a2a-477a-8356-424cc9d282f1",
   "metadata": {},
   "source": [
    "- **Goal**: teach the model to generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938cce4-79cd-4dd4-840d-f005e1b9d72f",
   "metadata": {},
   "source": [
    "### The training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a8c22-259f-41ff-8eb3-26354bff811e",
   "metadata": {},
   "source": [
    "The training data tells the model what we want it to predict. This could be texts and named entities we want to recognize, tokens and their correct part-of-speech tags or anything else the model should predict.\n",
    "\n",
    "To update an existing model, we can start with a few hundred to a few thousand examples.\n",
    "\n",
    "To train a new category we may need up to a million.\n",
    "\n",
    "spaCy's trained English pipelines for instance were trained on 2 million words labelled with part-of-speech tags, dependencies and named entities.\n",
    "\n",
    "Training data is usually created by humans who assign labels to texts.\n",
    "\n",
    "This is a lot of work, but can be semi-automated – for example, using spaCy's `Matcher`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43bd375-24e4-4ff0-a534-6cd7a30d4ee8",
   "metadata": {},
   "source": [
    "- Examples of what we want the model to predict in context\n",
    "- Update an **existing model**: a few hundred to a few thousand examples\n",
    "- Train a **new category**: a few thousand to a million examples\n",
    "  - spaCy's English models: 2 million words\n",
    "- Usually created manually by human annotators\n",
    "- Can be semi-automated – for example, using spaCy's `Matcher`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd2da22-18f0-4e77-b430-10c77172a983",
   "metadata": {},
   "source": [
    "### Training vs. evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1bd392-de06-43ed-927a-6ac340fe44c3",
   "metadata": {},
   "source": [
    "When training your model, it's important to know how it's doing and whether it's learning the right thing. This is done by comparing the model's predictions on examples it hasn't seen during training to answers we already know. So in addition to the training data, you also need evaluation data, also called development data.\n",
    "\n",
    "The evaluation data is used to calculate how accurate your model is. For example, an accuracy score of 90% means that the model predicted 90% of the evaluation examples correctly.\n",
    "\n",
    "This also means that the evaluation data needs to be representative of the data your model will see at runtime. Otherwise, the accuracy score will be meaningless, because it won't tell you how good your model *really* is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a77ae-c714-4294-aa33-7bcd93d0804a",
   "metadata": {},
   "source": [
    "- **Training data**: used to update the model\n",
    "- **Evaluation data**:\n",
    "  - data the model hasn't seen during training\n",
    "  - used to calculate how accurate the model is\n",
    "  - should be representative of the data the model will see at runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94717ff5-fe97-4d10-aaa0-fd660cf45d06",
   "metadata": {},
   "source": [
    "### Generating a training corpus (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba43402-9007-4dc8-8579-63b7fc324876",
   "metadata": {},
   "source": [
    "spaCy can be updated from data in the same format it creates: `Doc` objects. You already learned all about creating `Doc` and `Span` objects in chapter 2.\n",
    "\n",
    "In this example, we're creating two `Doc` objects for our corpus: one that contains an entity and another one that doesn't contain any entities. To set the entities on the `Doc`, we can add a `Span` to the `doc.ents`.\n",
    "\n",
    "Of course, you'll need a lot more examples to effectively train your model to generalize and predict similar entities in context. Depending on the task, you usually want at least a few hundred to a few thousand representative examples."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a7c6ebe-7e53-449c-a826-f9bd67cafee6",
   "metadata": {},
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create a Doc with entity spans\n",
    "doc1 = nlp(\"iPhone X is coming\")\n",
    "doc1.ents = [Span(doc1, 0, 2, label=\"GADGET\")]\n",
    "# Create another doc without entity spans\n",
    "doc2 = nlp(\"I need a new phone! Any tips?\")\n",
    "\n",
    "docs = [doc1, doc2]  # and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036e7fe4-adeb-42fe-a2bd-55aedaf3ee4d",
   "metadata": {},
   "source": [
    "### Generating a training corpus (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda277d-394d-4cc6-bf77-963d3f3bede3",
   "metadata": {},
   "source": [
    "As I mentioned earlier, we don't just need data to train the model. We also want to evaluate its accuracy on examples it hasn't seen during training. This is usually done by shuffling and splitting your data in two: one portion for training and one for evaluation. Here, we're using a simple 50/50 split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8487358c-f0b8-45ba-ba00-479b581f2b63",
   "metadata": {},
   "source": [
    "- split data into two portions:\n",
    "  - **training data**: used to update the model\n",
    "  - **development data**: used to evaluate the model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30cc072c-4205-4582-954a-1e44fbd7b850",
   "metadata": {},
   "source": [
    "random.shuffle(docs)\n",
    "train_docs = docs[:len(docs) // 2]\n",
    "dev_docs = docs[len(docs) // 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ed45d-d7a4-45f6-9c5e-c22097bbab6e",
   "metadata": {},
   "source": [
    "### Generating a training corpus (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceacc20-32e5-40ea-99cd-612a642426c7",
   "metadata": {},
   "source": [
    "You typically want to store your training and development data as files on disk so you can load them into spaCy's training process.\n",
    "\n",
    "The `DocBin` is a container for efficiently storing and serializing `Doc` objects. You can instantiate it with a list of `Doc` objects and call its `to_disk` method to save it to a binary file. We typically use the file extension `.spacy` for these files.\n",
    "\n",
    "Compared to other binary serialization protocols like `pickle`, the `DocBin` is faster and produces smaller file sizes because it only stores the shared vocabulary once. You can read more about how it works in the [documentation](https://spacy.io/api/docbin)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc05113-9090-4d20-be3c-e79aefd9b962",
   "metadata": {},
   "source": [
    "- `DocBin`: container to efficiently store and save `Doc` objects\n",
    "- can be saved to a binary file\n",
    "- binary files are used for training"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35b1bdbe-3285-4fd5-947d-b9c0c88af7cf",
   "metadata": {},
   "source": [
    "# Create and save a collection of training docs\n",
    "train_docbin = DocBin(docs=train_docs)\n",
    "train_docbin.to_disk(\"./train.spacy\")\n",
    "# Create and save a collection of evaluation docs\n",
    "dev_docbin = DocBin(docs=dev_docs)\n",
    "dev_docbin.to_disk(\"./dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8ec1a-32fc-4a11-b313-88687c4ea9b1",
   "metadata": {},
   "source": [
    "### Tip: Converting your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab2d3a-d6bf-4200-9e1e-8838e7c61081",
   "metadata": {},
   "source": [
    "In some cases, you might already have training and development data in a common format – for example, CoNLL or IOB. spaCy's `convert` command automatically converts these files into spaCy's binary format. It also converts JSON files in the old format used by spaCy v2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34964c2f-7b86-4dd8-bc69-3b5bc7ec3d0e",
   "metadata": {},
   "source": [
    "- `spacy convert` lets you convert corpora in common formats\n",
    "- supports `.conll`, `.conllu`, `.iob` and spaCy's old JSON format"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f918869-a85f-4b62-995e-cfbd53dfa410",
   "metadata": {},
   "source": [
    "$ python -m spacy convert ./train.gold.conll ./corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9eda0e-81e3-4ee2-bcae-554bd3343fbf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
